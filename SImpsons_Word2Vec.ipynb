{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /opt/anaconda3/lib/python3.7/site-packages (2.3.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/anaconda3/lib/python3.7/site-packages (from spacy) (0.8.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/anaconda3/lib/python3.7/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.7/site-packages (from spacy) (45.1.0.post20200127)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/lib/python3.7/site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from spacy) (3.0.4)\n",
      "Requirement already satisfied: thinc==7.4.1 in /opt/anaconda3/lib/python3.7/site-packages (from spacy) (7.4.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/anaconda3/lib/python3.7/site-packages (from spacy) (1.18.1)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/anaconda3/lib/python3.7/site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.7/site-packages (from spacy) (2.22.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/lib/python3.7/site-packages (from spacy) (4.42.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /opt/anaconda3/lib/python3.7/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from spacy) (2.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /opt/anaconda3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/anthonyzippay/Desktop/simpsons_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>spoken_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>No, actually, it was a little of both. Sometim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Where's Mr. Bergstrom?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>I don't know. Although I'd sure like to talk t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>That life is worth living.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Edna Krabappel-Flanders</td>\n",
       "      <td>The polls will be open from now until the end ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        raw_character_text                                       spoken_words\n",
       "0              Miss Hoover  No, actually, it was a little of both. Sometim...\n",
       "1             Lisa Simpson                             Where's Mr. Bergstrom?\n",
       "2              Miss Hoover  I don't know. Although I'd sure like to talk t...\n",
       "3             Lisa Simpson                         That life is worth living.\n",
       "4  Edna Krabappel-Flanders  The polls will be open from now until the end ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "raw_character_text    17814\n",
       "spoken_words          26459\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "raw_character_text    0\n",
       "spoken_words          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna().reset_index(drop=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['ner', 'parser'])\n",
    "\n",
    "def cleaning(doc):\n",
    "    txt = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    if len(txt) > 2:\n",
    "        return ' '.join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in df['spoken_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to clean up everything: 0.78 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "txt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000, n_threads=-1)]\n",
    "\n",
    "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85954, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = pd.DataFrame({'clean': txt})\n",
    "df_clean = df_clean.dropna().drop_duplicates()\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biagrams using Genism phrases package to auto detect common phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /opt/anaconda3/lib/python3.7/site-packages (3.8.3)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/anaconda3/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/anaconda3/lib/python3.7/site-packages (from gensim) (1.18.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /opt/anaconda3/lib/python3.7/site-packages (from gensim) (1.14.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/anaconda3/lib/python3.7/site-packages (from gensim) (3.0.0)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2019.11.28)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as phrases() takes a list of list of words as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [row.split() for row in df_clean['clean']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creates the relevant phrases from the list of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11:24:07: collecting all words and their counts\n",
      "INFO - 11:24:07: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "INFO - 11:24:08: PROGRESS: at sentence #10000, processed 63557 words and 52796 word types\n",
      "INFO - 11:24:08: PROGRESS: at sentence #20000, processed 130938 words and 99801 word types\n",
      "INFO - 11:24:08: PROGRESS: at sentence #30000, processed 192959 words and 138413 word types\n",
      "INFO - 11:24:08: PROGRESS: at sentence #40000, processed 249832 words and 172509 word types\n",
      "INFO - 11:24:08: PROGRESS: at sentence #50000, processed 311271 words and 208406 word types\n",
      "INFO - 11:24:08: PROGRESS: at sentence #60000, processed 373576 words and 243519 word types\n",
      "INFO - 11:24:08: PROGRESS: at sentence #70000, processed 436427 words and 278547 word types\n",
      "INFO - 11:24:08: PROGRESS: at sentence #80000, processed 497891 words and 311704 word types\n",
      "INFO - 11:24:08: collected 330480 word types from a corpus of 537095 words (unigram + bigrams) and 85954 sentences\n",
      "INFO - 11:24:08: using 330480 counts as vocab in Phrases<0 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n"
     ]
    }
   ],
   "source": [
    "phrases = Phrases(sent, min_count=30, progress_per=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of Phraser() is to cut down memory consumption of Phrases(), by discarding model state not strictly needed for the bigram detection task:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform the corpus based on the bigrams detected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11:24:08: source_vocab length 330480\n",
      "INFO - 11:24:10: Phraser built with 127 phrasegrams\n"
     ]
    }
   ],
   "source": [
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = bigram[sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30242"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq = defaultdict(int)\n",
    "for sent in sentences:\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most Frequent Words:\n",
    "check of the effectiveness of the lemmatization, removal of stopwords, and addition of bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oh', 'like', 'know', 'get', 'hey', 'think', 'come', 'right', 'look', 'want']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim Word2Vec Implementation:\n",
    "We use Gensim implementation of word2vec: https://radimrehurek.com/gensim/models/word2vec.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The parameters:\n",
    "min_count = int - Ignores all words with total absolute frequency lower than this - (2, 100)\n",
    "window = int - The maximum distance between the current and predicted word within a sentence. E.g. window words on the left and window words on the left of our target - (2, 10)\n",
    "size = int - Dimensionality of the feature vectors. - (50, 300)\n",
    "sample = float - The threshold for configuring which higher-frequency words are randomly downsampled. Highly influencial. - (0, 1e-5)\n",
    "alpha = float - The initial learning rate - (0.01, 0.05)\n",
    "min_alpha = float - Learning rate will linearly drop to min_alpha as training progresses. To set it: alpha - (min_alpha * epochs) ~ 0.00\n",
    "negative = int - If > 0, negative sampling will be used, the int for negative specifies how many \"noise words\" should be drown. If set to 0, no negative sampling is used. - (5, 20)\n",
    "workers = int - Use these many worker threads to train the model (=faster training with multicore machines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(min_count=20,\n",
    "                     window=2,\n",
    "                     size=300,\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=cores-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec requires us to build the vocabulary table (simply digesting all the words and filtering out the unique words, and doing some basic counts on them):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11:24:12: collecting all words and their counts\n",
      "INFO - 11:24:12: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 11:24:12: PROGRESS: at sentence #10000, processed 61710 words, keeping 9572 word types\n",
      "INFO - 11:24:12: PROGRESS: at sentence #20000, processed 127345 words, keeping 14535 word types\n",
      "INFO - 11:24:12: PROGRESS: at sentence #30000, processed 187806 words, keeping 17660 word types\n",
      "INFO - 11:24:12: PROGRESS: at sentence #40000, processed 243314 words, keeping 20424 word types\n",
      "INFO - 11:24:13: PROGRESS: at sentence #50000, processed 303176 words, keeping 22934 word types\n",
      "INFO - 11:24:13: PROGRESS: at sentence #60000, processed 363916 words, keeping 25246 word types\n",
      "INFO - 11:24:13: PROGRESS: at sentence #70000, processed 425379 words, keeping 27467 word types\n",
      "INFO - 11:24:13: PROGRESS: at sentence #80000, processed 485507 words, keeping 29350 word types\n",
      "INFO - 11:24:13: collected 30242 word types from a corpus of 523616 raw words and 85954 sentences\n",
      "INFO - 11:24:13: Loading a fresh vocabulary\n",
      "INFO - 11:24:13: effective_min_count=20 retains 3309 unique words (10% of original 30242, drops 26933)\n",
      "INFO - 11:24:13: effective_min_count=20 leaves 437086 word corpus (83% of original 523616, drops 86530)\n",
      "INFO - 11:24:13: deleting the raw counts dictionary of 30242 items\n",
      "INFO - 11:24:13: sample=6e-05 downsamples 1199 most-common words\n",
      "INFO - 11:24:13: downsampling leaves estimated 198624 word corpus (45.4% of prior 437086)\n",
      "INFO - 11:24:13: estimated required memory for 3309 words and 300 dimensions: 9596100 bytes\n",
      "INFO - 11:24:13: resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.03 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.build_vocab(sentences, progress_per=10000)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11:24:14: training model with 7 workers on 3309 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
      "INFO - 11:24:15: EPOCH 1 - PROGRESS: at 63.32% examples, 123398 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:24:15: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:24:15: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:24:15: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:24:15: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:24:15: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:24:15: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:24:15: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:24:15: EPOCH - 1 : training on 523616 raw words (198345 effective words) took 1.5s, 129467 effective words/s\n",
      "INFO - 11:24:16: EPOCH 2 - PROGRESS: at 65.22% examples, 123762 words/s, in_qsize 0, out_qsize 1\n",
      "INFO - 11:24:17: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:24:17: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:24:17: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:24:17: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:24:17: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:24:17: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:24:17: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:24:17: EPOCH - 2 : training on 523616 raw words (198260 effective words) took 1.5s, 131379 effective words/s\n",
      "INFO - 11:24:18: EPOCH 3 - PROGRESS: at 70.97% examples, 134365 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:24:18: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:24:18: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:24:18: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:24:18: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:24:18: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:24:18: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:24:18: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:24:18: EPOCH - 3 : training on 523616 raw words (198396 effective words) took 1.5s, 132131 effective words/s\n",
      "INFO - 11:24:19: EPOCH 4 - PROGRESS: at 67.19% examples, 132348 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:24:20: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:24:20: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:24:20: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:24:20: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:24:20: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:24:20: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:24:20: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:24:20: EPOCH - 4 : training on 523616 raw words (198528 effective words) took 1.4s, 137231 effective words/s\n",
      "INFO - 11:24:21: EPOCH 5 - PROGRESS: at 65.22% examples, 128511 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:24:21: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:24:21: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:24:21: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:24:21: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:24:21: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:24:21: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:24:21: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:24:21: EPOCH - 5 : training on 523616 raw words (198719 effective words) took 1.5s, 133561 effective words/s\n",
      "INFO - 11:24:22: EPOCH 6 - PROGRESS: at 65.22% examples, 127582 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:24:23: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:24:23: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:24:23: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:24:23: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:24:23: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:24:23: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:24:23: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:24:23: EPOCH - 6 : training on 523616 raw words (198322 effective words) took 1.5s, 130518 effective words/s\n",
      "INFO - 11:24:24: EPOCH 7 - PROGRESS: at 70.97% examples, 135669 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:24:24: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:24:24: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:24:24: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:24:24: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:24:24: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:24:24: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:24:24: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:24:24: EPOCH - 7 : training on 523616 raw words (198946 effective words) took 1.5s, 132517 effective words/s\n",
      "INFO - 11:24:25: EPOCH 8 - PROGRESS: at 70.97% examples, 134604 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:24:26: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:24:26: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:24:26: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:24:26: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:24:26: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:24:26: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:24:26: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:24:26: EPOCH - 8 : training on 523616 raw words (198713 effective words) took 1.4s, 137528 effective words/s\n",
      "INFO - 11:24:27: EPOCH 9 - PROGRESS: at 63.32% examples, 121883 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:24:27: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:24:27: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:24:27: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:24:27: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:24:27: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:24:27: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:24:27: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:24:27: EPOCH - 9 : training on 523616 raw words (198777 effective words) took 1.5s, 129820 effective words/s\n",
      "INFO - 11:24:28: EPOCH 10 - PROGRESS: at 63.32% examples, 119992 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:24:29: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:24:29: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:24:29: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:24:29: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:24:29: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:24:29: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:24:29: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:24:29: EPOCH - 10 : training on 523616 raw words (198531 effective words) took 1.5s, 128615 effective words/s\n",
      "INFO - 11:24:30: EPOCH 11 - PROGRESS: at 67.19% examples, 126982 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:24:30: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:24:30: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:24:30: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:24:30: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:24:30: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:24:30: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:24:30: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:24:30: EPOCH - 11 : training on 523616 raw words (198397 effective words) took 1.5s, 134135 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11:24:31: EPOCH 12 - PROGRESS: at 63.32% examples, 122583 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:24:32: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:24:32: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:24:32: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:24:32: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:24:32: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:24:32: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:24:32: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:24:32: EPOCH - 12 : training on 523616 raw words (198611 effective words) took 1.5s, 130457 effective words/s\n",
      "INFO - 11:24:33: EPOCH 13 - PROGRESS: at 63.32% examples, 123151 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:24:33: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:24:33: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:24:33: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:24:33: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:24:33: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:24:33: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:24:33: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:24:33: EPOCH - 13 : training on 523616 raw words (198436 effective words) took 1.5s, 130925 effective words/s\n",
      "INFO - 11:24:34: EPOCH 14 - PROGRESS: at 69.06% examples, 133282 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:24:35: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:24:35: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:24:35: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:24:35: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:24:35: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:24:35: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:24:35: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:24:35: EPOCH - 14 : training on 523616 raw words (198510 effective words) took 1.5s, 130965 effective words/s\n",
      "INFO - 11:24:36: EPOCH 15 - PROGRESS: at 69.06% examples, 133610 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:24:36: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:24:36: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:24:36: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:24:36: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:24:36: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:24:36: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:24:36: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:24:36: EPOCH - 15 : training on 523616 raw words (198581 effective words) took 1.4s, 138104 effective words/s\n",
      "INFO - 11:24:37: EPOCH 16 - PROGRESS: at 65.22% examples, 124764 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:24:38: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:24:38: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:24:38: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:24:38: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:24:38: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:24:38: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:24:38: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:24:38: EPOCH - 16 : training on 523616 raw words (198206 effective words) took 1.5s, 131189 effective words/s\n",
      "INFO - 11:24:39: EPOCH 17 - PROGRESS: at 63.32% examples, 123287 words/s, in_qsize 0, out_qsize 1\n",
      "INFO - 11:24:39: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:24:39: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:24:39: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:24:39: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:24:39: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:24:39: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:24:39: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:24:39: EPOCH - 17 : training on 523616 raw words (199002 effective words) took 1.5s, 131811 effective words/s\n",
      "INFO - 11:24:40: EPOCH 18 - PROGRESS: at 69.06% examples, 135744 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:24:41: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:24:41: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:24:41: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:24:41: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:24:41: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:24:41: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:24:41: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:24:41: EPOCH - 18 : training on 523616 raw words (198396 effective words) took 1.5s, 130296 effective words/s\n",
      "INFO - 11:24:42: EPOCH 19 - PROGRESS: at 70.97% examples, 134963 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:24:42: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:24:42: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:24:42: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:24:42: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:24:42: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:24:42: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:24:42: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:24:42: EPOCH - 19 : training on 523616 raw words (198423 effective words) took 1.4s, 138350 effective words/s\n",
      "INFO - 11:24:43: EPOCH 20 - PROGRESS: at 63.32% examples, 123247 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:24:44: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:24:44: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:24:44: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:24:44: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:24:44: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:24:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:24:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:24:44: EPOCH - 20 : training on 523616 raw words (198555 effective words) took 1.5s, 130697 effective words/s\n",
      "INFO - 11:24:45: EPOCH 21 - PROGRESS: at 63.32% examples, 123897 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:24:45: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:24:45: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:24:45: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:24:45: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:24:45: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:24:45: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:24:45: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:24:45: EPOCH - 21 : training on 523616 raw words (198767 effective words) took 1.5s, 133045 effective words/s\n",
      "INFO - 11:24:46: EPOCH 22 - PROGRESS: at 70.97% examples, 138898 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:24:47: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:24:47: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:24:47: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:24:47: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:24:47: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:24:47: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:24:47: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:24:47: EPOCH - 22 : training on 523616 raw words (198578 effective words) took 1.5s, 134136 effective words/s\n",
      "INFO - 11:24:48: EPOCH 23 - PROGRESS: at 70.97% examples, 137359 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11:24:48: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:24:48: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:24:48: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:24:48: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:24:48: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:24:48: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:24:48: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:24:48: EPOCH - 23 : training on 523616 raw words (198256 effective words) took 1.4s, 141571 effective words/s\n",
      "INFO - 11:24:49: EPOCH 24 - PROGRESS: at 65.22% examples, 126969 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:24:50: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:24:50: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:24:50: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:24:50: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:24:50: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:24:50: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:24:50: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:24:50: EPOCH - 24 : training on 523616 raw words (198874 effective words) took 1.5s, 134519 effective words/s\n",
      "INFO - 11:24:51: EPOCH 25 - PROGRESS: at 67.19% examples, 132359 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:24:51: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:24:51: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:24:51: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:24:51: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:24:51: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:24:51: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:24:51: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:24:51: EPOCH - 25 : training on 523616 raw words (198773 effective words) took 1.5s, 135531 effective words/s\n",
      "INFO - 11:24:52: EPOCH 26 - PROGRESS: at 67.19% examples, 132413 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:24:53: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:24:53: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:24:53: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:24:53: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:24:53: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:24:53: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:24:53: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:24:53: EPOCH - 26 : training on 523616 raw words (198588 effective words) took 1.5s, 136793 effective words/s\n",
      "INFO - 11:24:54: EPOCH 27 - PROGRESS: at 65.22% examples, 126015 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:24:54: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:24:54: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:24:54: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:24:54: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:24:54: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:24:54: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:24:54: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:24:54: EPOCH - 27 : training on 523616 raw words (198845 effective words) took 1.5s, 133662 effective words/s\n",
      "INFO - 11:24:55: EPOCH 28 - PROGRESS: at 63.32% examples, 124117 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:24:56: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:24:56: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:24:56: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:24:56: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:24:56: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:24:56: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:24:56: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:24:56: EPOCH - 28 : training on 523616 raw words (198267 effective words) took 1.5s, 130818 effective words/s\n",
      "INFO - 11:24:57: EPOCH 29 - PROGRESS: at 69.06% examples, 135813 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:24:57: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:24:57: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:24:57: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:24:57: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:24:57: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:24:57: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:24:57: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:24:57: EPOCH - 29 : training on 523616 raw words (198682 effective words) took 1.5s, 134308 effective words/s\n",
      "INFO - 11:24:58: EPOCH 30 - PROGRESS: at 70.97% examples, 137107 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:24:59: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:24:59: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:24:59: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:24:59: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:24:59: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:24:59: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:24:59: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:24:59: EPOCH - 30 : training on 523616 raw words (198402 effective words) took 1.4s, 141463 effective words/s\n",
      "INFO - 11:24:59: training on a 15708480 raw words (5956686 effective words) took 44.9s, 132693 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 0.78 mins\n"
     ]
    }
   ],
   "source": [
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11:24:59: precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the model\n",
    "Most similar to:\n",
    "Here, we will ask our model to find the word most similar to some of the most iconic characters of the Simpsons!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sweetheart', 0.7791968584060669),\n",
       " ('rude', 0.7722176313400269),\n",
       " ('embarrassing', 0.765440821647644),\n",
       " ('marge', 0.7588808536529541),\n",
       " ('gee', 0.7577983140945435),\n",
       " ('hammock', 0.7476896047592163),\n",
       " ('crummy', 0.742877721786499),\n",
       " ('good_friend', 0.7285328507423401),\n",
       " ('duh', 0.719735324382782),\n",
       " ('terrific', 0.7162286043167114)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"homer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lisa', 0.8628568053245544),\n",
       " ('hearing', 0.8464859127998352),\n",
       " ('convince', 0.8102348446846008),\n",
       " ('upset', 0.7956368327140808),\n",
       " ('homework', 0.7915209531784058),\n",
       " ('strangle', 0.7873169779777527),\n",
       " ('mom', 0.7869598865509033),\n",
       " ('exploit', 0.7823977470397949),\n",
       " ('surprised', 0.7791073322296143),\n",
       " ('grownup', 0.7773650884628296)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"bart\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('council', 0.7904050350189209),\n",
       " ('montgomery_burns', 0.7875198125839233),\n",
       " ('pleased', 0.7829771041870117),\n",
       " ('robert', 0.7803866863250732),\n",
       " ('waylon', 0.7780139446258545),\n",
       " ('select', 0.7718239426612854),\n",
       " ('easily', 0.7672803997993469),\n",
       " ('governor', 0.7651355266571045),\n",
       " ('threat', 0.763095498085022),\n",
       " ('recent', 0.7572838068008423)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"homer_simpson\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8871527"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity(\"moe\", 'tavern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70427865"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity(\"maggie\", 'baby')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74568856"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity(\"milhouse\", 'bart')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding those that dont match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 11:24:59: vectors for words {'kearney'} are not present in the model, ignoring these words\n",
      "/opt/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'jimbo'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.doesnt_match(['jimbo', 'milhouse', 'kearney'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nelson'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.doesnt_match([\"nelson\", \"bart\", \"milhouse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'homer'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.doesnt_match([\"patty\", \"selma\", \"homer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anology difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('admire', 0.6712377071380615),\n",
       " ('rude', 0.6696723699569702),\n",
       " ('attractive', 0.6556844711303711)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"woman\", \"homer\"], negative=[\"marge\"], topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this was supposed to show which word is most similar to woman as homer is to marge, but top result should be man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lisa', 0.7707328796386719),\n",
       " ('pregnant', 0.7573974132537842),\n",
       " ('upset', 0.6969519853591919)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"woman\", \"bart\"], negative=[\"man\"], topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-SNE visualizations:\n",
    "t-SNE is a non-linear dimensionality reduction algorithm that attempts to represent high-dimensional data and the underlying relationships between vectors in a lower-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    " \n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
